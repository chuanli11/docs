{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Run:AI For full documentation visit mkdocs.org . Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Home"},{"location":"#welcome-to-runai","text":"For full documentation visit mkdocs.org .","title":"Welcome to Run:AI"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"admin/admin/","text":"Administrator For full documentation visit mkdocs.org . Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files. Introduction The Admin User Interface allows: The setup of Kubernetes GPU Clusters. Create, Update and Delete of users Create, Update and Delete Projects. Review short term and long term dashboards Review Node and Job-status This document is about the Creation, Update, and Deletion of Users. Notes: With Run:AI you need to differentiate between the users of the Admin UI and Researcher users which submit workloads on the GPU Kubernetes cluster. This document is about the former. It is possible to connect the Admin UI users module to the organization's LDAP directory. For further information please contact Run:AI customer support. Working with Users Create User Note: to be able to manipulate users, you must have Administrator access. if you do not have such access, please contact an administrator. The list of administrators is shown on the Users page (see below) Log in to https://app.run.ai On the top left, open the menu and select \"Users\" On the top right, select \"Add New Users\". Choose a user name and email. Leave password as blank, it will be set by the user Select Roles. Note -- more than one role can be selected Select a Cluster. This determines the Clusters accessible to this user Press \"Save\" The user will receive a join mail and will be able to set a password. Update a User Select an existing User. Right-click and press \"Edit\" Update the values and press \"Save\" Delete an existing User Select an existing User. Right-click and press \"Delete\"","title":"Administrator"},{"location":"admin/admin/#administrator","text":"For full documentation visit mkdocs.org .","title":"Administrator"},{"location":"admin/admin/#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"admin/admin/#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"admin/admin/#introduction","text":"The Admin User Interface allows: The setup of Kubernetes GPU Clusters. Create, Update and Delete of users Create, Update and Delete Projects. Review short term and long term dashboards Review Node and Job-status This document is about the Creation, Update, and Deletion of Users. Notes: With Run:AI you need to differentiate between the users of the Admin UI and Researcher users which submit workloads on the GPU Kubernetes cluster. This document is about the former. It is possible to connect the Admin UI users module to the organization's LDAP directory. For further information please contact Run:AI customer support.","title":"Introduction"},{"location":"admin/admin/#working-with-users","text":"","title":"Working with Users"},{"location":"admin/admin/#create-user","text":"Note: to be able to manipulate users, you must have Administrator access. if you do not have such access, please contact an administrator. The list of administrators is shown on the Users page (see below) Log in to https://app.run.ai On the top left, open the menu and select \"Users\" On the top right, select \"Add New Users\". Choose a user name and email. Leave password as blank, it will be set by the user Select Roles. Note -- more than one role can be selected Select a Cluster. This determines the Clusters accessible to this user Press \"Save\" The user will receive a join mail and will be able to set a password.","title":"Create User"},{"location":"admin/admin/#update-a-user","text":"Select an existing User. Right-click and press \"Edit\" Update the values and press \"Save\"","title":"Update a User"},{"location":"admin/admin/#delete-an-existing-user","text":"Select an existing User. Right-click and press \"Delete\"","title":"Delete an existing User"},{"location":"admin/cluster-setup/install/","text":"Installing Run:AI on an on-premise Kubernetes Cluster The following are instructions on how to install Run:AI on the customer Kubernetes Cluster. Prior to installation please review the installation prerequisites here: https://support.run.ai/hc/en-us/articles/360010227960-Run-AI-GPU-Cluster-Prerequisites Step 1: Install Kubernetes Installing Kubernetes is beyond the scope of this guide. There are plenty of good ways to install Kubernetes (listed here: https://kubernetes.io/docs/setup/ ). We recommend Kubespray https://kubespray.io/#/ . Download the latest stable version from https://github.com/kubernetes-sigs/kubespray . The following next steps assume that you have the Kubernetes command-line kubectl on your laptop and that it is configured to point to the Kubernetes cluster (by running kubectl config use-context ) Step 2: NVIDIA On each machine with GPUs run the following steps 2.1 - 2.3: Step 2.1 Install NVIDIA Drivers If NVIDIA drivers are not already installed on your GPU machines, please install them now. Note that on original NVIDIA hardware, these drivers are already installed by default. Step 2.2: Install NVIDIA Docker Run the following: distribution=$(. /etc/os-release;echo $ID$VERSION_ID) curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list sudo apt-get update && sudo apt-get install -y nvidia-docker2 sudo pkill -SIGHUP dockerd Step 2.3: Make NVIDIA Docker the default docker runtime You will need to enable the Nvidia runtime as your default docker runtime on your node. We will be editing the docker daemon config file which is usually present at /etc/docker/daemon.json : { \" default-runtime \" : \" nvidia \" , \" runtimes \" : { \" nvidia \" : { \" path \" : \" /usr/bin/nvidia-container-runtime \" , \" runtimeArgs \" : [] } } } Then run the following again: sudo pkill -SIGHUP dockerd Step 3: Install Run:AI Log in to Run:AI at https://app.run.ai. Use credentials provided by Run:AI Customer Support to log in to the system If this is the first time anyone from your company has logged in, you will receive a dialog with instructions on how to install Run:AI on your Kubernetes Cluster. If not, open the menu on the top left and select \"Clusters\". On the top right-click \"Add New Cluster\". Continue according to instructions to install Run:AI on your Kubernetes Cluster Step 4: Verifying your Installation Go to https://app.run.ai Go to the Overview Dashboard Verify that the number of GPUs on the top right reflects your GPU resources on your cluster and the list of machines with GPU resources appear on the bottom line Next Steps Researchers work via a Command-line interface (CLI). See https://support.run.ai/hc/en-us/articles/360010706120-Installing-the-Run-AI-Command-Line-Interface on how to install the CLI for users Set up Admin UI Users. https://support.run.ai/hc/en-us/articles/360011591340-Working-with-Admin-UI-Users","title":"Installing Run:AI on an on-premise Kubernetes Cluster"},{"location":"admin/cluster-setup/install/#installing-runai-on-an-on-premise-kubernetes-cluster","text":"The following are instructions on how to install Run:AI on the customer Kubernetes Cluster. Prior to installation please review the installation prerequisites here: https://support.run.ai/hc/en-us/articles/360010227960-Run-AI-GPU-Cluster-Prerequisites","title":"Installing Run:AI on an on-premise Kubernetes Cluster"},{"location":"admin/cluster-setup/install/#step-1-install-kubernetes","text":"Installing Kubernetes is beyond the scope of this guide. There are plenty of good ways to install Kubernetes (listed here: https://kubernetes.io/docs/setup/ ). We recommend Kubespray https://kubespray.io/#/ . Download the latest stable version from https://github.com/kubernetes-sigs/kubespray . The following next steps assume that you have the Kubernetes command-line kubectl on your laptop and that it is configured to point to the Kubernetes cluster (by running kubectl config use-context )","title":"Step 1: Install Kubernetes"},{"location":"admin/cluster-setup/install/#step-2-nvidia","text":"On each machine with GPUs run the following steps 2.1 - 2.3:","title":"Step 2: NVIDIA"},{"location":"admin/cluster-setup/install/#step-21-install-nvidia-drivers","text":"If NVIDIA drivers are not already installed on your GPU machines, please install them now. Note that on original NVIDIA hardware, these drivers are already installed by default.","title":"Step 2.1 Install NVIDIA Drivers"},{"location":"admin/cluster-setup/install/#step-22-install-nvidia-docker","text":"Run the following: distribution=$(. /etc/os-release;echo $ID$VERSION_ID) curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list sudo apt-get update && sudo apt-get install -y nvidia-docker2 sudo pkill -SIGHUP dockerd","title":"Step 2.2: Install NVIDIA Docker"},{"location":"admin/cluster-setup/install/#step-23-make-nvidia-docker-the-default-docker-runtime","text":"You will need to enable the Nvidia runtime as your default docker runtime on your node. We will be editing the docker daemon config file which is usually present at /etc/docker/daemon.json : { \" default-runtime \" : \" nvidia \" , \" runtimes \" : { \" nvidia \" : { \" path \" : \" /usr/bin/nvidia-container-runtime \" , \" runtimeArgs \" : [] } } } Then run the following again: sudo pkill -SIGHUP dockerd","title":"Step 2.3: Make NVIDIA Docker the default docker runtime"},{"location":"admin/cluster-setup/install/#step-3-install-runai","text":"Log in to Run:AI at https://app.run.ai. Use credentials provided by Run:AI Customer Support to log in to the system If this is the first time anyone from your company has logged in, you will receive a dialog with instructions on how to install Run:AI on your Kubernetes Cluster. If not, open the menu on the top left and select \"Clusters\". On the top right-click \"Add New Cluster\". Continue according to instructions to install Run:AI on your Kubernetes Cluster","title":"Step 3: Install Run:AI"},{"location":"admin/cluster-setup/install/#step-4-verifying-your-installation","text":"Go to https://app.run.ai Go to the Overview Dashboard Verify that the number of GPUs on the top right reflects your GPU resources on your cluster and the list of machines with GPU resources appear on the bottom line","title":"Step 4: Verifying your Installation"},{"location":"admin/cluster-setup/install/#next-steps","text":"Researchers work via a Command-line interface (CLI). See https://support.run.ai/hc/en-us/articles/360010706120-Installing-the-Run-AI-Command-Line-Interface on how to install the CLI for users Set up Admin UI Users. https://support.run.ai/hc/en-us/articles/360011591340-Working-with-Admin-UI-Users","title":"Next Steps"},{"location":"admin/cluster-setup/prereq/","text":"Prerquisties Run:AI helps organizations optimize the resources of a data science operation. Below are the prerequisites of the Run:AI solution. Important note : This document relates to the cloud version of Run:AI and discusses the prerequisites for the GPU Cluster. Kubernetes Software Run:AI requires Kubernetes 1.15 or above. Kubernetes 1.17 is recommended (as of June 2020) Hardware Requirements Kubernetes Master: Run:AI runs on top of Kubernetes. If your GPU cluster already has Kubernetes, then no further hardware is required for Kubernetes. If you are installing Kubernetes, it is best (not mandatory) to have a separate machine that will act as the Kubernetes master . Such a machine is best with 4 CPUs and 8 GB RAM (with no special disk requirements) Shared data volume: Run:AI, via Kubernetes, abstracts away the machine on which a container is running. For containers to run anywhere, they need to be able to access data from any machine in a uniform way. Typically, this requires a NAS (Network-attached storage) which allows any node to connect to storage outside the box. Network Requirements Run:AI user interface runs from the cloud. All container nodes must be able to connect to the Run:AI cloud. Inbound connectivity (connecting from the cloud into nodes) is not required. If outbound connectivity is proxied/limited, the following exceptions should be applied: During Installation Run:AI requires an installation over the Kubernetes cluster. The installation access the web to download various images and registries. Some organizations place limitations on what you can pull from the internet. The following list shows the various solution components and their origin: Name Description URLs Ports Run:AI Repository The Run:AI Package Repository is hosted on Run:AI\u2019s account on Google Cloud [ runai-charts.storage.googleapis.com ](http://runai-charts.storage.googleapis.com/) 443 Docker Images Repository Various Run:AI images [ hub.docker.com ](http://hub.docker.com/) gcr.io/run-ai-prod 443 Docker Images Repository Various third party Images [ quay.io ](http://quay.io/) 443 Post Installation In addition, once running, Run:AI will send metrics to two sources: Name Description URLs Ports Grafana Grafana Metrics Server prometheus-us-central1.grafana.net 443 Run:AI Run:AI Cloud instance app.run.ai 443 User requirements Usage of containers and images: The individual researcher's work is based on container images. Containers allow IT to create standard software environments based on mix and match of various cutting-edge software","title":"Run:AI GPU Cluster Prerequisites"},{"location":"admin/cluster-setup/prereq/#prerquisties","text":"Run:AI helps organizations optimize the resources of a data science operation. Below are the prerequisites of the Run:AI solution. Important note : This document relates to the cloud version of Run:AI and discusses the prerequisites for the GPU Cluster.","title":"Prerquisties"},{"location":"admin/cluster-setup/prereq/#kubernetes-software","text":"Run:AI requires Kubernetes 1.15 or above. Kubernetes 1.17 is recommended (as of June 2020)","title":"Kubernetes Software"},{"location":"admin/cluster-setup/prereq/#hardware-requirements","text":"Kubernetes Master: Run:AI runs on top of Kubernetes. If your GPU cluster already has Kubernetes, then no further hardware is required for Kubernetes. If you are installing Kubernetes, it is best (not mandatory) to have a separate machine that will act as the Kubernetes master . Such a machine is best with 4 CPUs and 8 GB RAM (with no special disk requirements) Shared data volume: Run:AI, via Kubernetes, abstracts away the machine on which a container is running. For containers to run anywhere, they need to be able to access data from any machine in a uniform way. Typically, this requires a NAS (Network-attached storage) which allows any node to connect to storage outside the box.","title":"Hardware Requirements"},{"location":"admin/cluster-setup/prereq/#network-requirements","text":"Run:AI user interface runs from the cloud. All container nodes must be able to connect to the Run:AI cloud. Inbound connectivity (connecting from the cloud into nodes) is not required. If outbound connectivity is proxied/limited, the following exceptions should be applied:","title":"Network Requirements"},{"location":"admin/cluster-setup/prereq/#during-installation","text":"Run:AI requires an installation over the Kubernetes cluster. The installation access the web to download various images and registries. Some organizations place limitations on what you can pull from the internet. The following list shows the various solution components and their origin: Name Description URLs Ports Run:AI Repository The Run:AI Package Repository is hosted on Run:AI\u2019s account on Google Cloud [ runai-charts.storage.googleapis.com ](http://runai-charts.storage.googleapis.com/) 443 Docker Images Repository Various Run:AI images [ hub.docker.com ](http://hub.docker.com/) gcr.io/run-ai-prod 443 Docker Images Repository Various third party Images [ quay.io ](http://quay.io/) 443","title":"During Installation"},{"location":"admin/cluster-setup/prereq/#post-installation","text":"In addition, once running, Run:AI will send metrics to two sources: Name Description URLs Ports Grafana Grafana Metrics Server prometheus-us-central1.grafana.net 443 Run:AI Run:AI Cloud instance app.run.ai 443","title":"Post Installation"},{"location":"admin/cluster-setup/prereq/#user-requirements","text":"Usage of containers and images: The individual researcher's work is based on container images. Containers allow IT to create standard software environments based on mix and match of various cutting-edge software","title":"User requirements"}]}