{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Run:AI \u00b6","title":"Home"},{"location":"#welcome-to-runai","text":"","title":"Welcome to Run:AI"},{"location":"admin/admin/","text":"Administrator \u00b6 For full documentation visit mkdocs.org . Commands \u00b6 mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout \u00b6 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files. Introduction \u00b6 The Admin User Interface allows: The setup of Kubernetes GPU Clusters. Create, Update and Delete of users Create, Update and Delete Projects. Review short term and long term dashboards Review Node and Job-status This document is about the Creation, Update, and Deletion of Users. Notes: With Run:AI you need to differentiate between the users of the Admin UI and Researcher users which submit workloads on the GPU Kubernetes cluster. This document is about the former. It is possible to connect the Admin UI users module to the organization's LDAP directory. For further information please contact Run:AI customer support. Working with Users \u00b6 Create User \u00b6 Note: to be able to manipulate users, you must have Administrator access. if you do not have such access, please contact an administrator. The list of administrators is shown on the Users page (see below) Log in to https://app.run.ai On the top left, open the menu and select \"Users\" On the top right, select \"Add New Users\". Choose a user name and email. Leave password as blank, it will be set by the user Select Roles. Note -- more than one role can be selected Select a Cluster. This determines the Clusters accessible to this user Press \"Save\" The user will receive a join mail and will be able to set a password. Update a User \u00b6 Select an existing User. Right-click and press \"Edit\" Update the values and press \"Save\" Delete an existing User \u00b6 Select an existing User. Right-click and press \"Delete\"","title":"Administrator"},{"location":"admin/admin/#administrator","text":"For full documentation visit mkdocs.org .","title":"Administrator"},{"location":"admin/admin/#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"admin/admin/#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"admin/admin/#introduction","text":"The Admin User Interface allows: The setup of Kubernetes GPU Clusters. Create, Update and Delete of users Create, Update and Delete Projects. Review short term and long term dashboards Review Node and Job-status This document is about the Creation, Update, and Deletion of Users. Notes: With Run:AI you need to differentiate between the users of the Admin UI and Researcher users which submit workloads on the GPU Kubernetes cluster. This document is about the former. It is possible to connect the Admin UI users module to the organization's LDAP directory. For further information please contact Run:AI customer support.","title":"Introduction"},{"location":"admin/admin/#working-with-users","text":"","title":"Working with Users"},{"location":"admin/admin/#create-user","text":"Note: to be able to manipulate users, you must have Administrator access. if you do not have such access, please contact an administrator. The list of administrators is shown on the Users page (see below) Log in to https://app.run.ai On the top left, open the menu and select \"Users\" On the top right, select \"Add New Users\". Choose a user name and email. Leave password as blank, it will be set by the user Select Roles. Note -- more than one role can be selected Select a Cluster. This determines the Clusters accessible to this user Press \"Save\" The user will receive a join mail and will be able to set a password.","title":"Create User"},{"location":"admin/admin/#update-a-user","text":"Select an existing User. Right-click and press \"Edit\" Update the values and press \"Save\"","title":"Update a User"},{"location":"admin/admin/#delete-an-existing-user","text":"Select an existing User. Right-click and press \"Delete\"","title":"Delete an existing User"},{"location":"admin/cluster-setup/install/","text":"Installing Run:AI on an on-premise Kubernetes Cluster \u00b6 The following are instructions on how to install Run:AI on the customer Kubernetes Cluster. Prior to installation please review the installation prerequisites here: https://support.run.ai/hc/en-us/articles/360010227960-Run-AI-GPU-Cluster-Prerequisites Step 1: Install Kubernetes \u00b6 Installing Kubernetes is beyond the scope of this guide. There are plenty of good ways to install Kubernetes (listed here: https://kubernetes.io/docs/setup/ ). We recommend Kubespray https://kubespray.io/#/ . Download the latest stable version from https://github.com/kubernetes-sigs/kubespray . The following next steps assume that you have the Kubernetes command-line kubectl on your laptop and that it is configured to point to the Kubernetes cluster (by running kubectl config use-context ) Step 2: NVIDIA \u00b6 On each machine with GPUs run the following steps 2.1 - 2.3: Step 2.1 Install NVIDIA Drivers \u00b6 If NVIDIA drivers are not already installed on your GPU machines, please install them now. Note that on original NVIDIA hardware, these drivers are already installed by default. Step 2.2: Install NVIDIA Docker \u00b6 Run the following: distribution=$(. /etc/os-release;echo $ID$VERSION_ID) curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list sudo apt-get update && sudo apt-get install -y nvidia-docker2 sudo pkill -SIGHUP dockerd Step 2.3: Make NVIDIA Docker the default docker runtime \u00b6 You will need to enable the Nvidia runtime as your default docker runtime on your node. We will be editing the docker daemon config file which is usually present at /etc/docker/daemon.json : { \"default-runtime\": \"nvidia\", \"runtimes\": { \"nvidia\": { \"path\": \"/usr/bin/nvidia-container-runtime\", \"runtimeArgs\": [] } } } Then run the following again: sudo pkill -SIGHUP dockerd Step 3: Install Run:AI \u00b6 Log in to Run:AI at https://app.run.ai. Use credentials provided by Run:AI Customer Support to log in to the system If this is the first time anyone from your company has logged in, you will receive a dialog with instructions on how to install Run:AI on your Kubernetes Cluster. If not, open the menu on the top left and select \"Clusters\". On the top right-click \"Add New Cluster\". Continue according to instructions to install Run:AI on your Kubernetes Cluster Step 4: Verifying your Installation \u00b6 Go to https://app.run.ai Go to the Overview Dashboard Verify that the number of GPUs on the top right reflects your GPU resources on your cluster and the list of machines with GPU resources appear on the bottom line Next Steps \u00b6 Researchers work via a Command-line interface (CLI). See https://support.run.ai/hc/en-us/articles/360010706120-Installing-the-Run-AI-Command-Line-Interface on how to install the CLI for users Set up Admin UI Users. https://support.run.ai/hc/en-us/articles/360011591340-Working-with-Admin-UI-Users","title":"Installing Run:AI on an on-premise Kubernetes Cluster"},{"location":"admin/cluster-setup/install/#installing-runai-on-an-on-premise-kubernetes-cluster","text":"The following are instructions on how to install Run:AI on the customer Kubernetes Cluster. Prior to installation please review the installation prerequisites here: https://support.run.ai/hc/en-us/articles/360010227960-Run-AI-GPU-Cluster-Prerequisites","title":"Installing Run:AI on an on-premise Kubernetes Cluster"},{"location":"admin/cluster-setup/install/#step-1-install-kubernetes","text":"Installing Kubernetes is beyond the scope of this guide. There are plenty of good ways to install Kubernetes (listed here: https://kubernetes.io/docs/setup/ ). We recommend Kubespray https://kubespray.io/#/ . Download the latest stable version from https://github.com/kubernetes-sigs/kubespray . The following next steps assume that you have the Kubernetes command-line kubectl on your laptop and that it is configured to point to the Kubernetes cluster (by running kubectl config use-context )","title":"Step 1: Install Kubernetes"},{"location":"admin/cluster-setup/install/#step-2-nvidia","text":"On each machine with GPUs run the following steps 2.1 - 2.3:","title":"Step 2: NVIDIA"},{"location":"admin/cluster-setup/install/#step-21-install-nvidia-drivers","text":"If NVIDIA drivers are not already installed on your GPU machines, please install them now. Note that on original NVIDIA hardware, these drivers are already installed by default.","title":"Step 2.1 Install NVIDIA Drivers"},{"location":"admin/cluster-setup/install/#step-22-install-nvidia-docker","text":"Run the following: distribution=$(. /etc/os-release;echo $ID$VERSION_ID) curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list sudo apt-get update && sudo apt-get install -y nvidia-docker2 sudo pkill -SIGHUP dockerd","title":"Step 2.2: Install NVIDIA Docker"},{"location":"admin/cluster-setup/install/#step-23-make-nvidia-docker-the-default-docker-runtime","text":"You will need to enable the Nvidia runtime as your default docker runtime on your node. We will be editing the docker daemon config file which is usually present at /etc/docker/daemon.json : { \"default-runtime\": \"nvidia\", \"runtimes\": { \"nvidia\": { \"path\": \"/usr/bin/nvidia-container-runtime\", \"runtimeArgs\": [] } } } Then run the following again: sudo pkill -SIGHUP dockerd","title":"Step 2.3: Make NVIDIA Docker the default docker runtime"},{"location":"admin/cluster-setup/install/#step-3-install-runai","text":"Log in to Run:AI at https://app.run.ai. Use credentials provided by Run:AI Customer Support to log in to the system If this is the first time anyone from your company has logged in, you will receive a dialog with instructions on how to install Run:AI on your Kubernetes Cluster. If not, open the menu on the top left and select \"Clusters\". On the top right-click \"Add New Cluster\". Continue according to instructions to install Run:AI on your Kubernetes Cluster","title":"Step 3: Install Run:AI"},{"location":"admin/cluster-setup/install/#step-4-verifying-your-installation","text":"Go to https://app.run.ai Go to the Overview Dashboard Verify that the number of GPUs on the top right reflects your GPU resources on your cluster and the list of machines with GPU resources appear on the bottom line","title":"Step 4: Verifying your Installation"},{"location":"admin/cluster-setup/install/#next-steps","text":"Researchers work via a Command-line interface (CLI). See https://support.run.ai/hc/en-us/articles/360010706120-Installing-the-Run-AI-Command-Line-Interface on how to install the CLI for users Set up Admin UI Users. https://support.run.ai/hc/en-us/articles/360011591340-Working-with-Admin-UI-Users","title":"Next Steps"},{"location":"admin/cluster-setup/prereq/","text":"Prerquisties \u00b6 Run:AI helps organizations optimize the resources of a data science operation. Below are the prerequisites of the Run:AI solution. Important note : This document relates to the cloud version of Run:AI and discusses the prerequisites for the GPU Cluster. Kubernetes Software \u00b6 Run:AI requires Kubernetes 1.15 or above. Kubernetes 1.17 is recommended (as of June 2020) Hardware Requirements \u00b6 Kubernetes Master: Run:AI runs on top of Kubernetes. If your GPU cluster already has Kubernetes, then no further hardware is required for Kubernetes. If you are installing Kubernetes, it is best (not mandatory) to have a separate machine that will act as the Kubernetes master . Such a machine is best with 4 CPUs and 8 GB RAM (with no special disk requirements) Shared data volume: Run:AI, via Kubernetes, abstracts away the machine on which a container is running. For containers to run anywhere, they need to be able to access data from any machine in a uniform way. Typically, this requires a NAS (Network-attached storage) which allows any node to connect to storage outside the box. Network Requirements \u00b6 Run:AI user interface runs from the cloud. All container nodes must be able to connect to the Run:AI cloud. Inbound connectivity (connecting from the cloud into nodes) is not required. If outbound connectivity is proxied/limited, the following exceptions should be applied: During Installation \u00b6 Run:AI requires an installation over the Kubernetes cluster. The installation access the web to download various images and registries. Some organizations place limitations on what you can pull from the internet. The following list shows the various solution components and their origin: Name Description URLs Ports Run:AI Repository The Run:AI Package Repository is hosted on Run:AI\u2019s account on Google Cloud [ runai-charts.storage.googleapis.com ](http://runai-charts.storage.googleapis.com/) 443 Docker Images Repository Various Run:AI images [ hub.docker.com ](http://hub.docker.com/) gcr.io/run-ai-prod 443 Docker Images Repository Various third party Images [ quay.io ](http://quay.io/) 443 Post Installation \u00b6 In addition, once running, Run:AI will send metrics to two sources: Name Description URLs Ports Grafana Grafana Metrics Server prometheus-us-central1.grafana.net 443 Run:AI Run:AI Cloud instance app.run.ai 443 User requirements \u00b6 Usage of containers and images: The individual researcher's work is based on container images. Containers allow IT to create standard software environments based on mix and match of various cutting-edge software","title":"Run:AI GPU Cluster Prerequisites"},{"location":"admin/cluster-setup/prereq/#prerquisties","text":"Run:AI helps organizations optimize the resources of a data science operation. Below are the prerequisites of the Run:AI solution. Important note : This document relates to the cloud version of Run:AI and discusses the prerequisites for the GPU Cluster.","title":"Prerquisties"},{"location":"admin/cluster-setup/prereq/#kubernetes-software","text":"Run:AI requires Kubernetes 1.15 or above. Kubernetes 1.17 is recommended (as of June 2020)","title":"Kubernetes Software"},{"location":"admin/cluster-setup/prereq/#hardware-requirements","text":"Kubernetes Master: Run:AI runs on top of Kubernetes. If your GPU cluster already has Kubernetes, then no further hardware is required for Kubernetes. If you are installing Kubernetes, it is best (not mandatory) to have a separate machine that will act as the Kubernetes master . Such a machine is best with 4 CPUs and 8 GB RAM (with no special disk requirements) Shared data volume: Run:AI, via Kubernetes, abstracts away the machine on which a container is running. For containers to run anywhere, they need to be able to access data from any machine in a uniform way. Typically, this requires a NAS (Network-attached storage) which allows any node to connect to storage outside the box.","title":"Hardware Requirements"},{"location":"admin/cluster-setup/prereq/#network-requirements","text":"Run:AI user interface runs from the cloud. All container nodes must be able to connect to the Run:AI cloud. Inbound connectivity (connecting from the cloud into nodes) is not required. If outbound connectivity is proxied/limited, the following exceptions should be applied:","title":"Network Requirements"},{"location":"admin/cluster-setup/prereq/#during-installation","text":"Run:AI requires an installation over the Kubernetes cluster. The installation access the web to download various images and registries. Some organizations place limitations on what you can pull from the internet. The following list shows the various solution components and their origin: Name Description URLs Ports Run:AI Repository The Run:AI Package Repository is hosted on Run:AI\u2019s account on Google Cloud [ runai-charts.storage.googleapis.com ](http://runai-charts.storage.googleapis.com/) 443 Docker Images Repository Various Run:AI images [ hub.docker.com ](http://hub.docker.com/) gcr.io/run-ai-prod 443 Docker Images Repository Various third party Images [ quay.io ](http://quay.io/) 443","title":"During Installation"},{"location":"admin/cluster-setup/prereq/#post-installation","text":"In addition, once running, Run:AI will send metrics to two sources: Name Description URLs Ports Grafana Grafana Metrics Server prometheus-us-central1.grafana.net 443 Run:AI Run:AI Cloud instance app.run.ai 443","title":"Post Installation"},{"location":"admin/cluster-setup/prereq/#user-requirements","text":"Usage of containers and images: The individual researcher's work is based on container images. Containers allow IT to create standard software environments based on mix and match of various cutting-edge software","title":"User requirements"},{"location":"researcher/api-reference/bash/","text":"runai bash \u00b6 Description \u00b6 Get a bash session inside a running job Synopsis \u00b6 <runai bash <job-name> [--backward-compatibility | -b] [--loglevel <value>] [--project <string> | -p <string>] [--help | -h] Options \u00b6 Global Flags \u00b6 --backward-compatibility | -b Backward compatibility mode to provide support for Jobs created with older versions of the CLI. See here for further information --loglevel (string) Set the logging level. One of: debug|info|warn|error (default \"info\") --project | -p (string) Specify the project to which the command applies. By default, commands apply to the default project. To change the default project use 'runai project set '. --help | -h Show help text Output \u00b6 The command will access the container that should be currently running in the current cluster and attempt to create a command line shell based on bash. The command will return an error if the container does not exist or has not been in running state yet. See also \u00b6 Build Workloads: https://support.run.ai/hc/en-us/articles/360010894959-Walkthrough-Start-and-Use-Interactive-Build-Workloads-","title":"runai bash"},{"location":"researcher/api-reference/bash/#runai-bash","text":"","title":"runai bash"},{"location":"researcher/api-reference/bash/#description","text":"Get a bash session inside a running job","title":"Description"},{"location":"researcher/api-reference/bash/#synopsis","text":"<runai bash <job-name> [--backward-compatibility | -b] [--loglevel <value>] [--project <string> | -p <string>] [--help | -h]","title":"Synopsis"},{"location":"researcher/api-reference/bash/#options","text":"","title":"Options"},{"location":"researcher/api-reference/bash/#global-flags","text":"--backward-compatibility | -b Backward compatibility mode to provide support for Jobs created with older versions of the CLI. See here for further information --loglevel (string) Set the logging level. One of: debug|info|warn|error (default \"info\") --project | -p (string) Specify the project to which the command applies. By default, commands apply to the default project. To change the default project use 'runai project set '. --help | -h Show help text","title":"Global Flags"},{"location":"researcher/api-reference/bash/#output","text":"The command will access the container that should be currently running in the current cluster and attempt to create a command line shell based on bash. The command will return an error if the container does not exist or has not been in running state yet.","title":"Output"},{"location":"researcher/api-reference/bash/#see-also","text":"Build Workloads: https://support.run.ai/hc/en-us/articles/360010894959-Walkthrough-Start-and-Use-Interactive-Build-Workloads-","title":"See also"},{"location":"researcher/api-reference/submit/","text":"runai submit \u00b6 Description \u00b6 Submit a Run:AI job for execution Synopsis \u00b6 runai submit [--always-pull-image] [--args ] [--backoffLimit ] [--command ] [--cpu ] [--cpu-limit ] [--elastic] [--environment | -e ] [--gpu | -g ] [--host-ipc] [--host-network] [--image | -i ] [--interactive] [--jupyter] [--large-shm] [--local-image] [--memory ] [--memory-limit ] [--node-type ] [--port ] [--preemptible] [-- run-as-user] [--service-type | -s ] [--template ] [--ttl-after-finish ] [--volume | -v stringArray] [ --working-dir] [--loglevel ] [--project | -p ] [--help | -h] Syntax notes: Options with value type of stringArray mean that you can add multiple values. You can either separate values with a comma or add the flag twice. Options \u00b6 the name of the job to run the command in the command itself (e.g. bash ) --always-pull-image When starting a container, always pull the image from repository, even if cached on running node. This is useful when you are re-saving updates to the image using the same tag. --args Arguments to pass to the command run on container start. Use together with --command. Example: --command sleep --args 10000 -- backoffLimit The number of times the job will be retried before failing. Default is 6. This flag will only work with training workloads (when the --interactive flag is not specified) --command Command to run at container start. Use together with --args . --cpu CPU units to allocate for the job (0.5, 1, .etc). The Job will receive at least this amount of CPU. Note that the Job will not be scheduled unless the system can guarantee this amount of CPUs to the job. --cpu-limit Limitations of the number of CPU consumed by the job (0.5, 1, .etc). The system guarantees that this Job will not be able to consume more than this amount of GPUs. -- elastic Mark the job as elastic. For further information on Elasticity see https://support.run.ai/hc/en-us/articles/360011347560-Elasticity-Dynamically-Stretch-Compress-Jobs-According-to-GPU-Availability -e | --environment Define environment variables to be set in the container. To set multiple values add the flag multiple times (-e BATCH_SIZE=50 -e LEARNING_RATE=0.2) or separate by a comma (-e BATCH_SIZE:50,LEARNING_RATE:0.2) --gpu | -g Number of GPUs to allocation to the Job. Default is no GPUs. --host-ipc Use the host's ipc namespace. Controls whether the pod containers can share the host IPC namespace. IPC (POSIX/SysV IPC) namespace provides separation of named shared memory segments, semaphores and message queues. Shared memory segments are used to accelerate inter-process communication at memory speed, rather than through pipes or through the network stack For further information see docker documentation --host-network Use the host's network stack inside the container For further information see docker documentation --image | -i Image to use when creating the container for this Job --interactive Mark this Job as Interactive. Interactive jobs are not terminated automatically by the system --jupyter (Deprecated) Shortcut for running a jupyter notebook container. Uses a pre-created image and a default notebook configuration. Use the templates flag instead. --large-shm Mount a large /dev/shm device. shm is a shared file system mounted on RAM --local-image Use a local image for this job. A local image is an image which exists on all local servers of the Kubernetes Cluster. --memory CPU memory to allocate for this job (1G, 20M, .etc). The Job will receive at least this amount of memory. Note that the Job will not be scheduled unless the system can guarantee this amount of memory to the job. --memory-limit CPU memory to allocate for this job (1G, 20M, .etc). The system guarantees that this Job will not be able to consume more than this amount of memory. The Job will receive an error when trying to allocate more memory than this limit. --name (Deprecated) Job Name. Add the name without the --name flag. --node-type Allows defining specific nodes (machines) or group of nodes on which the workload will run. To use this feature your administrator will need to label nodes as explained here: https://support.run.ai/hc/en-us/articles/360011591500-Limit-a-Workload-to-a-Specific-Node-Group This flag can be used in conjunction with Project-based affinity. In this case, the flag is used to refine the list of allowable node groups set in the project. For more information see: https://support.run.ai/hc/en-us/articles/360011591300-Working-with-Projects --port Expose ports from the Job container. Used together with --service-type. Examples: --port 8080:80 --service-type loadbalancer --port 8080 --service-type ingress --preemptible Mark an interactive job as preemptible. Preemptible jobs can be scheduled above guaranteed quota but may be reclaimed at any time. --run-as-user Run in the context of the current user running the Run:AI command rather than the root user. While the default container user is root (same as in Docker), this command allows you to submit a job running under your linux user. This would manifest itself in access to operating system resources, in the owner of new folders created under shared directories etc. --service-type | -s Service exposure method for interactive Job. Options are: portforward, loadbalancer, nodeport, ingress. Use the command runai list to obtain the endpoint to use the service when the job is running. Different service methods have different endpoint structure --template Use a specific template when running this job. Templates are set by the cluster administrator and provide predefined values to flags under the submit command. If a template is not set, a default template will be use if such exists --ttl-after-finish Define the duration, post job finish, after which the job is automatically deleted (5s, 2m, 3h, .etc). Note: This setting must first be enabled at the cluster level. See https://support.run.ai/hc/en-us/articles/360011623839-Automatically-Delete-Jobs-After-Job-Finish --volume | -v Volume to mount into the container. Example -v /raid/public/john/data:/root/data:ro The flag may optionally be suffixed with :ro or :rw to mount the volumes in read-only or read-write mode, respectively. --working-dir Starts the container with the specified directory Global Flags \u00b6 --loglevel (string) Set the logging level. One of: debug|info|warn|error (default \"info\") --project | -p (string) Specify the project to which the command applies. Run:AI Projects are used by the scheduler to calculate resource eligibility. By default, commands apply to the default project. To change the default project use 'runai project set '. --help | -h Show help text Examples \u00b6 start an unattended training job of name run1, based on project team-ny using a quickstart image: runai submit run1 -i gcr.io/run-ai-lab/quickstart -g 1 -p team-ny start an interactive job of name run2, based on project team-ny using a jupyter notebook image. The Notebook will be externalized via a load balancer on port 8888: runai submit run2 -i jupyter/base-notebook -g 1 \\ -p team-ny --interactive --service-type=loadbalancer --port 8888:8888 Output \u00b6 The command will attempt to submit a job. You can follow up on the job by running runai list or runai get -e Note that the submit call may use templates to provide defaults to any of the above flags. See Also \u00b6 See any of the Walkthrough documents here: https://support.run.ai/hc/en-us/articles/360010773460-Run-AI-Walkthroughs See runai template https://support.run.ai/hc/en-us/articles/360011548039-runai-template for a description on how templates work","title":"runai submit"},{"location":"researcher/api-reference/submit/#runai-submit","text":"","title":"runai submit"},{"location":"researcher/api-reference/submit/#description","text":"Submit a Run:AI job for execution","title":"Description"},{"location":"researcher/api-reference/submit/#synopsis","text":"runai submit [--always-pull-image] [--args ] [--backoffLimit ] [--command ] [--cpu ] [--cpu-limit ] [--elastic] [--environment | -e ] [--gpu | -g ] [--host-ipc] [--host-network] [--image | -i ] [--interactive] [--jupyter] [--large-shm] [--local-image] [--memory ] [--memory-limit ] [--node-type ] [--port ] [--preemptible] [-- run-as-user] [--service-type | -s ] [--template ] [--ttl-after-finish ] [--volume | -v stringArray] [ --working-dir] [--loglevel ] [--project | -p ] [--help | -h] Syntax notes: Options with value type of stringArray mean that you can add multiple values. You can either separate values with a comma or add the flag twice.","title":"Synopsis"},{"location":"researcher/api-reference/submit/#options","text":"the name of the job to run the command in the command itself (e.g. bash ) --always-pull-image When starting a container, always pull the image from repository, even if cached on running node. This is useful when you are re-saving updates to the image using the same tag. --args Arguments to pass to the command run on container start. Use together with --command. Example: --command sleep --args 10000 -- backoffLimit The number of times the job will be retried before failing. Default is 6. This flag will only work with training workloads (when the --interactive flag is not specified) --command Command to run at container start. Use together with --args . --cpu CPU units to allocate for the job (0.5, 1, .etc). The Job will receive at least this amount of CPU. Note that the Job will not be scheduled unless the system can guarantee this amount of CPUs to the job. --cpu-limit Limitations of the number of CPU consumed by the job (0.5, 1, .etc). The system guarantees that this Job will not be able to consume more than this amount of GPUs. -- elastic Mark the job as elastic. For further information on Elasticity see https://support.run.ai/hc/en-us/articles/360011347560-Elasticity-Dynamically-Stretch-Compress-Jobs-According-to-GPU-Availability -e | --environment Define environment variables to be set in the container. To set multiple values add the flag multiple times (-e BATCH_SIZE=50 -e LEARNING_RATE=0.2) or separate by a comma (-e BATCH_SIZE:50,LEARNING_RATE:0.2) --gpu | -g Number of GPUs to allocation to the Job. Default is no GPUs. --host-ipc Use the host's ipc namespace. Controls whether the pod containers can share the host IPC namespace. IPC (POSIX/SysV IPC) namespace provides separation of named shared memory segments, semaphores and message queues. Shared memory segments are used to accelerate inter-process communication at memory speed, rather than through pipes or through the network stack For further information see docker documentation --host-network Use the host's network stack inside the container For further information see docker documentation --image | -i Image to use when creating the container for this Job --interactive Mark this Job as Interactive. Interactive jobs are not terminated automatically by the system --jupyter (Deprecated) Shortcut for running a jupyter notebook container. Uses a pre-created image and a default notebook configuration. Use the templates flag instead. --large-shm Mount a large /dev/shm device. shm is a shared file system mounted on RAM --local-image Use a local image for this job. A local image is an image which exists on all local servers of the Kubernetes Cluster. --memory CPU memory to allocate for this job (1G, 20M, .etc). The Job will receive at least this amount of memory. Note that the Job will not be scheduled unless the system can guarantee this amount of memory to the job. --memory-limit CPU memory to allocate for this job (1G, 20M, .etc). The system guarantees that this Job will not be able to consume more than this amount of memory. The Job will receive an error when trying to allocate more memory than this limit. --name (Deprecated) Job Name. Add the name without the --name flag. --node-type Allows defining specific nodes (machines) or group of nodes on which the workload will run. To use this feature your administrator will need to label nodes as explained here: https://support.run.ai/hc/en-us/articles/360011591500-Limit-a-Workload-to-a-Specific-Node-Group This flag can be used in conjunction with Project-based affinity. In this case, the flag is used to refine the list of allowable node groups set in the project. For more information see: https://support.run.ai/hc/en-us/articles/360011591300-Working-with-Projects --port Expose ports from the Job container. Used together with --service-type. Examples: --port 8080:80 --service-type loadbalancer --port 8080 --service-type ingress --preemptible Mark an interactive job as preemptible. Preemptible jobs can be scheduled above guaranteed quota but may be reclaimed at any time. --run-as-user Run in the context of the current user running the Run:AI command rather than the root user. While the default container user is root (same as in Docker), this command allows you to submit a job running under your linux user. This would manifest itself in access to operating system resources, in the owner of new folders created under shared directories etc. --service-type | -s Service exposure method for interactive Job. Options are: portforward, loadbalancer, nodeport, ingress. Use the command runai list to obtain the endpoint to use the service when the job is running. Different service methods have different endpoint structure --template Use a specific template when running this job. Templates are set by the cluster administrator and provide predefined values to flags under the submit command. If a template is not set, a default template will be use if such exists --ttl-after-finish Define the duration, post job finish, after which the job is automatically deleted (5s, 2m, 3h, .etc). Note: This setting must first be enabled at the cluster level. See https://support.run.ai/hc/en-us/articles/360011623839-Automatically-Delete-Jobs-After-Job-Finish --volume | -v Volume to mount into the container. Example -v /raid/public/john/data:/root/data:ro The flag may optionally be suffixed with :ro or :rw to mount the volumes in read-only or read-write mode, respectively. --working-dir Starts the container with the specified directory","title":"Options"},{"location":"researcher/api-reference/submit/#global-flags","text":"--loglevel (string) Set the logging level. One of: debug|info|warn|error (default \"info\") --project | -p (string) Specify the project to which the command applies. Run:AI Projects are used by the scheduler to calculate resource eligibility. By default, commands apply to the default project. To change the default project use 'runai project set '. --help | -h Show help text","title":"Global Flags"},{"location":"researcher/api-reference/submit/#examples","text":"start an unattended training job of name run1, based on project team-ny using a quickstart image: runai submit run1 -i gcr.io/run-ai-lab/quickstart -g 1 -p team-ny start an interactive job of name run2, based on project team-ny using a jupyter notebook image. The Notebook will be externalized via a load balancer on port 8888: runai submit run2 -i jupyter/base-notebook -g 1 \\ -p team-ny --interactive --service-type=loadbalancer --port 8888:8888","title":"Examples"},{"location":"researcher/api-reference/submit/#output","text":"The command will attempt to submit a job. You can follow up on the job by running runai list or runai get -e Note that the submit call may use templates to provide defaults to any of the above flags.","title":"Output"},{"location":"researcher/api-reference/submit/#see-also","text":"See any of the Walkthrough documents here: https://support.run.ai/hc/en-us/articles/360010773460-Run-AI-Walkthroughs See runai template https://support.run.ai/hc/en-us/articles/360011548039-runai-template for a description on how templates work","title":"See Also"}]}